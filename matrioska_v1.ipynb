{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3uw0inKtuNS0",
      "metadata": {
        "id": "3uw0inKtuNS0"
      },
      "source": [
        "# Matrioska - Sistema de OrquestraÃ§Ã£o de LLM com Estado Compartilhado\n",
        "\n",
        "![Matrioska](https://live.staticflickr.com/8646/16075618524_6f3b5b199e_b.jpg)\n",
        "\n",
        "## ðŸ“‹ VisÃ£o Geral\n",
        "\n",
        "**Matrioska** Ã© um sistema avanÃ§ado de orquestraÃ§Ã£o para modelos de linguagem grande (LLMs) que implementa uma arquitetura modular com estado compartilhado. Inspirado no conceito das bonecas russas, o sistema decompÃµe tarefas complexas em mÃ³dulos especializados que se comunicam atravÃ©s de um quadro branco compartilhado.\n",
        "\n",
        "## ðŸŽ¯ Funcionalidades Principais\n",
        "\n",
        "- **ðŸ§© DecomposiÃ§Ã£o ArquitetÃ´nica**: Divide automaticamente tarefas complexas em mÃ³dulos especializados\n",
        "- **ðŸ§  Estado Compartilhado**: Sistema de comunicaÃ§Ã£o entre mÃ³dulos via `shared_state`\n",
        "- **ðŸ’¾ PersistÃªncia de Contexto**: Salva e restaura o progresso entre execuÃ§Ãµes\n",
        "- **âš¡ ExecuÃ§Ã£o em Hiperfoco**: Cada mÃ³dulo executa com foco especÃ­fico\n",
        "- **ðŸ”— IntegraÃ§Ã£o Inteligente**: Combina artefatos mantendo consistÃªncia\n",
        "- **â³ Simplicidade e Reaproveitamento**: Busca gerar cÃ³digos simplÃ³rios e usar CDNs/Bibliotecas\n",
        "\n",
        "## ðŸ—ï¸ Arquitetura\n",
        "\n",
        "### Componentes Principais\n",
        "\n",
        "1. **`LocalLLM`** - Wrapper para modelos Mistral com quantizaÃ§Ã£o 4-bit\n",
        "2. **`MatrioskaOrchestrator`** - Orquestrador principal do pipeline\n",
        "3. **`ContextManager`** - Gerenciador de estado e persistÃªncia\n",
        "4. **`Architecture`** - Estrutura de dados para planejamento modular\n",
        "\n",
        "### Fluxo de ExecuÃ§Ã£o\n",
        "\n",
        "```\n",
        "FASE 1: ARQUITETURA â†’ FASE 2: EXECUÃ‡ÃƒO â†’ FASE 3: MONTAGEM\n",
        "    â†“                      â†“                    â†“\n",
        " DecomposiÃ§Ã£o        ExecuÃ§Ã£o Modular    IntegraÃ§Ã£o Final\n",
        "```\n",
        "\n",
        "## ðŸš€ Como Usar\n",
        "\n",
        "### InstalaÃ§Ã£o\n",
        "\n",
        "```bash\n",
        "pip install transformers accelerate bitsandbytes torch sentencepiece protobuf # requirements.txt with specific versions in github repo\n",
        "```\n",
        "\n",
        "### ExecuÃ§Ã£o BÃ¡sica\n",
        "\n",
        "```python\n",
        "from matrioska import LocalLLM, MatrioskaOrchestrator\n",
        "\n",
        "# Inicializar modelo\n",
        "llm = LocalLLM(\"mistralai/Mistral-7B-Instruct-v0.3\")\n",
        "orchestrator = MatrioskaOrchestrator(llm, base_path=\"/content\")\n",
        "\n",
        "# Executar tarefa\n",
        "result = orchestrator.run(\"Criar sistema de gerenciamento de biblioteca com dashboard\")\n",
        "```\n",
        "\n",
        "### Estrutura de DiretÃ³rios\n",
        "\n",
        "```\n",
        "/content/\n",
        "â”œâ”€â”€ matrioska_artifacts/     # Artefatos gerados por mÃ³dulo\n",
        "â”œâ”€â”€ matrioska_checkpoints/   # Estado compartilhado e arquitetura\n",
        "â”‚   â”œâ”€â”€ shared_state.json    # Quadro branco compartilhado\n",
        "â”‚   â””â”€â”€ architecture.json    # Plano arquitetural\n",
        "â””â”€â”€ matrioska_results.zip    # Download de resultados\n",
        "```\n",
        "\n",
        "## ðŸ“– Sistema de MÃ³dulos\n",
        "\n",
        "### EspecificaÃ§Ã£o de MÃ³dulo\n",
        "\n",
        "```python\n",
        "@dataclass\n",
        "class ModuleSpec:\n",
        "    id: str                    # Identificador Ãºnico\n",
        "    name: str                  # Nome descritivo\n",
        "    description: str           # DescriÃ§Ã£o da funcionalidade\n",
        "    inputs: str               # DependÃªncias de entrada\n",
        "    outputs: str              # SaÃ­das esperadas\n",
        "    dependencies: List[str]   # MÃ³dulos predecessores\n",
        "    rules: str                # Regras especÃ­ficas\n",
        "    shared_state_reads: List[str]  # Chaves de leitura\n",
        "    shared_state_writes: List[str] # Chaves de escrita\n",
        "```\n",
        "\n",
        "### Exemplo de ComunicaÃ§Ã£o\n",
        "\n",
        "```python\n",
        "# MÃ³dulo A gera IDs\n",
        "shared_state_updates = {\n",
        "    \"element_ids\": [\"#loginForm\", \"#bookList\", \"#dashboardStats\"],\n",
        "    \"page_structure\": {\"login\": \"...\", \"catalog\": \"...\"}\n",
        "}\n",
        "\n",
        "# MÃ³dulo B consome IDs\n",
        "context = context_manager.get_shared_context([\"element_ids\"])\n",
        "```\n",
        "\n",
        "## ðŸ”§ ConfiguraÃ§Ã£o do Modelo\n",
        "\n",
        "### QuantizaÃ§Ã£o 4-bit\n",
        "\n",
        "```python\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        ")\n",
        "```\n",
        "\n",
        "### ParÃ¢metros de GeraÃ§Ã£o\n",
        "\n",
        "- **max_tokens**: 4000\n",
        "- **temperature**: 0.3\n",
        "- **top_p**: 0.85\n",
        "- **do_sample**: True\n",
        "\n",
        "## ðŸ“Š Prompt de Arquitetura\n",
        "\n",
        "O sistema usa um prompt especializado (`ARCHITECT_SYSTEM_PROMPT`) para decompor tarefas, definindo:\n",
        "\n",
        "- **Objetivo geral** do projeto\n",
        "- **MÃ³dulos especializados** com dependÃªncias\n",
        "- **Contratos de comunicaÃ§Ã£o** via shared_state\n",
        "- **Manuais especÃ­ficos** para cada mÃ³dulo\n",
        "\n",
        "## ðŸ’¡ Casos de Uso\n",
        "\n",
        "### Desenvolvimento Web\n",
        "```python\n",
        "result = orchestrator.run('''\n",
        "Criar aplicaÃ§Ã£o React com:\n",
        "- AutenticaÃ§Ã£o JWT\n",
        "- CRUD de produtos\n",
        "- Dashboard administrativo\n",
        "- Design responsivo\n",
        "''')\n",
        "```\n",
        "\n",
        "### Processamento de Dados\n",
        "```python\n",
        "result = orchestrator.run('''\n",
        "Sistema de anÃ¡lise de dados com:\n",
        "- ExtraÃ§Ã£o de APIs REST\n",
        "- Limpeza e transformaÃ§Ã£o\n",
        "- VisualizaÃ§Ãµes interativas\n",
        "- RelatÃ³rios automÃ¡ticos\n",
        "''')\n",
        "```\n",
        "\n",
        "## ðŸŽ¨ Exemplo de SaÃ­da\n",
        "\n",
        "```\n",
        "ðŸª† MATRIOSKA ORCHESTRATOR - Hiperfoco + SharedState\n",
        "================================================================================\n",
        "\n",
        "ðŸ—ï¸  FASE 1: ARQUITETURA\n",
        "--------------------------------------------------------------------------------\n",
        "ðŸ“‹ Tarefa: 'Library management system with dashboard'\n",
        "\n",
        "âœ“ Projeto: Library Management System\n",
        "âœ“ Objetivo: Create a complete library management system with authentication, CRUD, and dashboard\n",
        "âœ“ MÃ³dulos: 3\n",
        "   1. HTML Structure ðŸ“–[] âœï¸['element_ids', 'page_structure']\n",
        "   2. CSS Styling ðŸ“–['element_ids', 'page_structure'] âœï¸['css_classes', 'color_scheme']\n",
        "   3. Authentication Logic ðŸ“–['element_ids'] âœï¸['auth_api', 'storage_keys']\n",
        "\n",
        "âš¡ FASE 2: EXECUÃ‡ÃƒO (Hiperfoco + ComunicaÃ§Ã£o)\n",
        "--------------------------------------------------------------------------------\n",
        "ðŸŽ¯ HTML Structure\n",
        "   âœ“ Gerado (1542 chars)\n",
        "\n",
        "ðŸŽ¯ CSS Styling\n",
        "   ðŸ“– Lendo contexto: ['element_ids', 'page_structure']\n",
        "   âœï¸ Escreveu: ['css_classes', 'color_scheme']\n",
        "   âœ“ Gerado (2387 chars)\n",
        "\n",
        "ðŸ”§ FASE 3: MONTAGEM\n",
        "--------------------------------------------------------------------------------\n",
        "ðŸ”— Integrando artefatos...\n",
        "\n",
        "âœ… RESULTADO FINAL\n",
        "================================================================================\n",
        "ðŸ“¦ Library Management System\n",
        "ðŸŽ¯ Create a complete library management system with authentication, CRUD, and dashboard\n",
        "\n",
        "ðŸ“‚ Artefatos: 3\n",
        "ðŸ§  SharedState Keys: ['element_ids', 'page_structure', 'css_classes', 'color_scheme', 'auth_api']\n",
        "\n",
        "ðŸ”— Resultado Integrado:\n",
        "--------------------------------------------------------------------------------\n",
        "[Sistema completo integrado...]\n",
        "```\n",
        "\n",
        "## ðŸ”„ GestÃ£o de Estado\n",
        "\n",
        "### Shared State\n",
        "- **Persistente**: Sobrevive entre reinicializaÃ§Ãµes\n",
        "- **Estruturado**: DicionÃ¡rio JSON serializÃ¡vel\n",
        "- **Seletivo**: MÃ³dulos acessam apenas chaves relevantes\n",
        "\n",
        "### Checkpoints\n",
        "- Arquitetura salva em `architecture.json`\n",
        "- Estado compartilhado em `shared_state.json`\n",
        "- Artefatos individuais em arquivos texto\n",
        "\n",
        "## ðŸ“¦ ExportaÃ§Ã£o de Resultados\n",
        "\n",
        "```python\n",
        "# Download completo dos resultados\n",
        "from google.colab import files\n",
        "!zip -r matrioska_results.zip /content/matrioska_artifacts /content/matrioska_checkpoints\n",
        "files.download('matrioska_results.zip')\n",
        "```\n",
        "\n",
        "## ðŸ› ï¸ Requisitos TÃ©cnicos\n",
        "\n",
        "- **GPU**: NVIDIA T4 (8GB VRAM) ou superior\n",
        "- **RAM**: 16GB+\n",
        "- **Python**: 3.8+\n",
        "- **Bibliotecas**: transformers, torch, bitsandbytes, sentencepiece\n",
        "\n",
        "## ðŸ”® Roadmap\n",
        "\n",
        "- [ ] Suporte a mÃºltiplos modelos LLM\n",
        "- [ ] Interface web para monitoramento\n",
        "- [ ] Sistema de plugins para mÃ³dulos customizados\n",
        "- [ ] OtimizaÃ§Ã£o de memÃ³ria para projetos grandes\n",
        "- [ ] IntegraÃ§Ã£o com controle de versÃ£o\n",
        "\n",
        "## ðŸ“„ LicenÃ§a\n",
        "\n",
        "Este projeto Ã© destinado para fins de pesquisa e desenvolvimento.\n",
        "\n",
        "---\n",
        "\n",
        "**Matrioska**: Transformando complexidade em modularidade inteligente ðŸª†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8Y6IqCbauRxi",
      "metadata": {
        "id": "8Y6IqCbauRxi"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers accelerate bitsandbytes torch sentencepiece protobuf # requirements.txt with specific versions in github repo\n",
        "\n",
        "import json\n",
        "import os\n",
        "import torch\n",
        "from dataclasses import dataclass, asdict, field\n",
        "from typing import List, Optional, Dict, Any\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62PMVQKnz_Kl",
      "metadata": {
        "id": "62PMVQKnz_Kl"
      },
      "outputs": [],
      "source": [
        "_MAX_TOKEN_ = 4000\n",
        "\n",
        "ARCHITECT_SYSTEM_PROMPT = \"\"\"You are Matrioska Architect. Decompose user requests into isolated modules that communicate via shared_state.\n",
        "\n",
        "RULES:\n",
        "1. Each module can READ from shared_state (dependencies)\n",
        "2. Each module can WRITE to shared_state (outputs)\n",
        "3. Specify exactly what each module reads/writes\n",
        "4. CODE GUIDELINES:\n",
        "   - Keep implementation concepts SIMPLE and CLEAN\n",
        "   - Prefer direct, minimal solutions over complex ones\n",
        "   - You may suggest using CDNs (Bootstrap, SweetAlert, etc.)\n",
        "   - You may suggest libraries (Flask, SQLAlchemy, etc.) listed in requirements.txt or similar if relevant\n",
        "   - Avoid complex build systems unless strictly required\n",
        "   - Include only essential dependencies\n",
        "\n",
        "EXAMPLE:\n",
        "Request: \"Library management system with dashboard\"\n",
        "Output: {\n",
        "  \"project_name\": \"Library Management System\",\n",
        "  \"general_manual\": {\n",
        "    \"goal\": \"Create a complete library management system with authentication, CRUD, and dashboard\",\n",
        "    \"modules\": [\n",
        "      {\n",
        "        \"id\": \"html_structure\",\n",
        "        \"name\": \"HTML Structure\",\n",
        "        \"description\": \"Design all HTML pages and navigation layout\",\n",
        "        \"inputs\": \"design requirements\",\n",
        "        \"outputs\": \"HTML page structure with element IDs\",\n",
        "        \"dependencies\": [],\n",
        "        \"rules\": \"Use semantic HTML5 and IDs. Keep structure simple. You may suggest Bootstrap via CDN for layout.\",\n",
        "        \"shared_state_reads\": [],\n",
        "        \"shared_state_writes\": [\"element_ids\", \"page_structure\"]\n",
        "      },\n",
        "      {\n",
        "        \"id\": \"css_styling\",\n",
        "        \"name\": \"CSS Styling\",\n",
        "        \"description\": \"Define visual style for all pages\",\n",
        "        \"inputs\": \"HTML structure\",\n",
        "        \"outputs\": \"CSS file or theme reference\",\n",
        "        \"dependencies\": [\"html_structure\"],\n",
        "        \"rules\": \"Use element_ids from shared_state. May suggest Bootstrap themes or custom CSS. Keep style cohesive and simple.\",\n",
        "        \"shared_state_reads\": [\"element_ids\", \"page_structure\"],\n",
        "        \"shared_state_writes\": [\"css_classes\", \"color_scheme\"]\n",
        "      },\n",
        "      {\n",
        "        \"id\": \"auth_logic\",\n",
        "        \"name\": \"Authentication Logic\",\n",
        "        \"description\": \"Login/logout using localStorage or backend API\",\n",
        "        \"inputs\": \"HTML IDs\",\n",
        "        \"outputs\": \"Auth logic plan\",\n",
        "        \"dependencies\": [\"html_structure\"],\n",
        "        \"rules\": \"Use element_ids. May suggest SweetAlert for alerts. Keep logic lightweight and avoid heavy frameworks.\",\n",
        "        \"shared_state_reads\": [\"element_ids\"],\n",
        "        \"shared_state_writes\": [\"auth_api\", \"storage_keys\"]\n",
        "      },\n",
        "      {\n",
        "        \"id\": \"backend_api\",\n",
        "        \"name\": \"Backend API (Python)\",\n",
        "        \"description\": \"Define backend API endpoints and dependencies\",\n",
        "        \"inputs\": \"functional requirements\",\n",
        "        \"outputs\": \"API contract and dependency list\",\n",
        "        \"dependencies\": [\"auth_logic\"],\n",
        "        \"rules\": \"Propose a simple Flask or FastAPI backend. List dependencies in requirements.txt (e.g. Flask, SQLAlchemy).\",\n",
        "        \"shared_state_reads\": [\"auth_api\"],\n",
        "        \"shared_state_writes\": [\"api_routes\", \"db_models\"]\n",
        "      }\n",
        "    ],\n",
        "    \"integration_rules\": \"Combine all modules ensuring consistent shared_state keys. Use CDNs in HTML suggestions and requirements.txt for backend dependencies.\"\n",
        "  },\n",
        "  \"specific_manuals\": [\n",
        "    {\n",
        "      \"module_id\": \"html_structure\",\n",
        "      \"manual_text\": \"Define HTML structure for login, catalog, and dashboard pages. Use IDs like #loginForm, #bookList, #dashboardStats. Mention that Bootstrap via CDN may be used for layout consistency. Extract all IDs and write them to shared_state as 'element_ids'.\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\n",
        "NOW PROCESS THIS REQUEST:\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nhHdTyXvtzUF",
      "metadata": {
        "id": "nhHdTyXvtzUF"
      },
      "outputs": [],
      "source": [
        "class LocalLLM:\n",
        "    \"\"\"Local LLM for T4 (16GB VRAM)\"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = \"mistralai/Mistral-7B-Instruct-v0.3\"):\n",
        "        print(f\"ðŸ”„ Loading {model_name}...\")\n",
        "\n",
        "        quant_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_compute_dtype=torch.float16,\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "            bnb_4bit_quant_type=\"nf4\"\n",
        "        )\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            quantization_config=quant_config,\n",
        "            device_map=\"auto\",\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        self.model_name = model_name\n",
        "        print(f\"âœ… Model loaded: {model_name}\")\n",
        "        print(f\"ðŸ’¾ VRAM used: {torch.cuda.memory_allocated()/1024**3:.2f}GB\")\n",
        "\n",
        "    def generate(self, prompt: str, max_tokens: int = _MAX_TOKEN_, system: str = \"\") -> str:\n",
        "        \"\"\"Optimized generation\"\"\"\n",
        "        if system:\n",
        "            full_prompt = f\"{system}\\n\\n{prompt}\"\n",
        "        else:\n",
        "            full_prompt = prompt\n",
        "\n",
        "        inputs = self.tokenizer(full_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=max_tokens,\n",
        "                temperature=0.3,\n",
        "                top_p=0.85,\n",
        "                do_sample=True,\n",
        "                pad_token_id=self.tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        response = self.tokenizer.decode(\n",
        "            outputs[0][inputs['input_ids'].shape[1]:],\n",
        "            skip_special_tokens=True\n",
        "        )\n",
        "\n",
        "        log_dir = \"/content/log\"\n",
        "        log_file = os.path.join(log_dir, \"log.txt\")\n",
        "        os.makedirs(log_dir, exist_ok=True)\n",
        "        with open(log_file, \"a\") as f:\n",
        "            f.write(\"PROMPT:\\n==========================================\\n\\n\")\n",
        "            f.write(full_prompt)\n",
        "            f.write(\"\\n==========================================\\n\")\n",
        "            f.write(\"RESULT:\\n==========================================\\n\\n\")\n",
        "            f.write(response.strip())\n",
        "            f.write(\"\\n\\n\\n\\n\")\n",
        "\n",
        "        return response.strip()\n",
        "\n",
        "@dataclass\n",
        "class ModuleSpec:\n",
        "    id: str\n",
        "    name: str\n",
        "    description: str\n",
        "    inputs: str\n",
        "    outputs: str\n",
        "    dependencies: List[str]\n",
        "    rules: str\n",
        "    shared_state_reads: List[str] = field(default_factory=list)\n",
        "    shared_state_writes: List[str] = field(default_factory=list)\n",
        "\n",
        "@dataclass\n",
        "class GeneralManual:\n",
        "    goal: str\n",
        "    modules: List[ModuleSpec]\n",
        "    integration_rules: str\n",
        "\n",
        "@dataclass\n",
        "class SpecificManual:\n",
        "    module_id: str\n",
        "    manual_text: str\n",
        "\n",
        "@dataclass\n",
        "class Architecture:\n",
        "    project_name: str\n",
        "    general_manual: GeneralManual\n",
        "    specific_manuals: List[SpecificManual]\n",
        "\n",
        "@dataclass\n",
        "class ModuleArtifact:\n",
        "    module_id: str\n",
        "    name: str\n",
        "    content: str\n",
        "    shared_state_updates: Dict[str, Any] = field(default_factory=dict)\n",
        "\n",
        "class ContextManager:\n",
        "    def __init__(self, base_path: str = \"/content\"):\n",
        "        self.base_path = base_path\n",
        "        self.artifacts_dir = os.path.join(base_path, \"matrioska_artifacts\")\n",
        "        self.checkpoints_dir = os.path.join(base_path, \"matrioska_checkpoints\")\n",
        "        self.shared_state_file = os.path.join(self.checkpoints_dir, \"shared_state.json\")\n",
        "\n",
        "        os.makedirs(self.artifacts_dir, exist_ok=True)\n",
        "        os.makedirs(self.checkpoints_dir, exist_ok=True)\n",
        "\n",
        "        self.shared_state: Dict[str, Any] = self._load_shared_state()\n",
        "\n",
        "    def _load_shared_state(self) -> Dict[str, Any]:\n",
        "        \"\"\"Load shared state\"\"\"\n",
        "        try:\n",
        "            with open(self.shared_state_file, \"r\", encoding=\"utf-8\") as f:\n",
        "                state = json.load(f)\n",
        "                print(\"ðŸ§  [SHARED STATE] Context recovered\")\n",
        "                return state\n",
        "        except FileNotFoundError:\n",
        "            print(\"ðŸ§  [SHARED STATE] Starting new context\")\n",
        "            return {}\n",
        "\n",
        "    def _save_shared_state(self):\n",
        "        \"\"\"Persist shared state\"\"\"\n",
        "        with open(self.shared_state_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(self.shared_state, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    def update_shared_state(self, updates: Dict[str, Any]):\n",
        "        \"\"\"Update whiteboard\"\"\"\n",
        "        self.shared_state.update(updates)\n",
        "        self._save_shared_state()\n",
        "        print(f\"ðŸ§  [SHARED STATE] Updated: {list(updates.keys())}\")\n",
        "\n",
        "    def get_shared_context(self, keys: List[str]) -> Dict[str, Any]:\n",
        "        \"\"\"Retrieve relevant context for module\"\"\"\n",
        "        context = {}\n",
        "        for key in keys:\n",
        "            if key in self.shared_state:\n",
        "                context[key] = self.shared_state[key]\n",
        "        return context\n",
        "\n",
        "    def save_architecture(self, arch: Architecture):\n",
        "        filepath = os.path.join(self.checkpoints_dir, \"architecture.json\")\n",
        "        with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump({\n",
        "                \"project_name\": arch.project_name,\n",
        "                \"general_manual\": {\n",
        "                    \"goal\": arch.general_manual.goal,\n",
        "                    \"modules\": [asdict(m) for m in arch.general_manual.modules],\n",
        "                    \"integration_rules\": arch.general_manual.integration_rules\n",
        "                },\n",
        "                \"specific_manuals\": [asdict(m) for m in arch.specific_manuals]\n",
        "            }, f, indent=2, ensure_ascii=False)\n",
        "        print(f\"ðŸ’¾ [CHECKPOINT] Architecture â†’ {filepath}\")\n",
        "\n",
        "    def load_architecture(self) -> Optional[Architecture]:\n",
        "        filepath = os.path.join(self.checkpoints_dir, \"architecture.json\")\n",
        "        try:\n",
        "            with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            modules = [ModuleSpec(**m) for m in data[\"general_manual\"][\"modules\"]]\n",
        "            general = GeneralManual(\n",
        "                goal=data[\"general_manual\"][\"goal\"],\n",
        "                modules=modules,\n",
        "                integration_rules=data[\"general_manual\"][\"integration_rules\"]\n",
        "            )\n",
        "            specific = [SpecificManual(**m) for m in data[\"specific_manuals\"]]\n",
        "\n",
        "            print(\"ðŸ“‚ [RESTORATION] Context recovered\")\n",
        "            return Architecture(\n",
        "                project_name=data[\"project_name\"],\n",
        "                general_manual=general,\n",
        "                specific_manuals=specific\n",
        "            )\n",
        "        except FileNotFoundError:\n",
        "            return None\n",
        "\n",
        "    def save_artifact(self, artifact: ModuleArtifact):\n",
        "        filename = os.path.join(self.artifacts_dir, f\"{artifact.module_id}.txt\")\n",
        "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(artifact.content)\n",
        "        print(f\"ðŸ’¾ {artifact.name} â†’ {filename}\")\n",
        "\n",
        "    def get_artifacts_path(self) -> str:\n",
        "        return self.artifacts_dir\n",
        "\n",
        "class MatrioskaOrchestrator:\n",
        "    def __init__(self, llm: LocalLLM, base_path: str = \"/content\"):\n",
        "        self.llm = llm\n",
        "        self.context_manager = ContextManager(base_path)\n",
        "\n",
        "    def run(self, task: str, verbose: bool = True):\n",
        "        \"\"\"Main pipeline with SharedState\"\"\"\n",
        "        if verbose:\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"ðŸª† matrioska ORCHESTRATOR - Hyperfocus + SharedState\")\n",
        "            print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "        if verbose:\n",
        "            print(\"ðŸ—ï¸  PHASE 1: ARCHITECTURE\")\n",
        "            print(\"-\" * 80)\n",
        "        architecture = self._architecture_phase(task, verbose)\n",
        "\n",
        "        if not architecture:\n",
        "            return None\n",
        "\n",
        "        self.context_manager.save_architecture(architecture)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"\\nâš¡ PHASE 2: EXECUTION (Hyperfocus + Communication)\")\n",
        "            print(\"-\" * 80)\n",
        "        artifacts = self._execution_phase(architecture, verbose)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"\\nðŸ”§ PHASE 3: ASSEMBLY\")\n",
        "            print(\"-\" * 80)\n",
        "        restored_arch = self.context_manager.load_architecture()\n",
        "        final_result = self._assembly_phase(restored_arch, artifacts, verbose)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"\\nâœ… FINAL RESULT\")\n",
        "            print(\"=\" * 80)\n",
        "            self._display_results(architecture, artifacts, final_result)\n",
        "            print(\"=\" * 80)\n",
        "            print(f\"\\nðŸ“ Artifacts: {self.context_manager.get_artifacts_path()}\")\n",
        "            print(f\"ðŸ§  SharedState: {self.context_manager.shared_state_file}\")\n",
        "\n",
        "        return {\n",
        "            \"architecture\": architecture,\n",
        "            \"artifacts\": artifacts,\n",
        "            \"final_result\": final_result,\n",
        "            \"shared_state\": self.context_manager.shared_state\n",
        "        }\n",
        "\n",
        "    def _architecture_phase(self, task: str, verbose: bool) -> Optional[Architecture]:\n",
        "        \"\"\"Architectural decomposition\"\"\"\n",
        "        if verbose:\n",
        "            print(f\"ðŸ“‹ Task: '{task}'\")\n",
        "\n",
        "        response = self.llm.generate(task, max_tokens=_MAX_TOKEN_, system=ARCHITECT_SYSTEM_PROMPT)\n",
        "\n",
        "        try:\n",
        "            start = response.find(\"{\")\n",
        "            end = response.rfind(\"}\") + 1\n",
        "            if start == -1 or end == 0:\n",
        "                raise ValueError(\"JSON not found\")\n",
        "\n",
        "            json_str = response[start:end]\n",
        "            data = json.loads(json_str)\n",
        "\n",
        "            modules = [ModuleSpec(**m) for m in data[\"general_manual\"][\"modules\"]]\n",
        "            general = GeneralManual(\n",
        "                goal=data[\"general_manual\"][\"goal\"],\n",
        "                modules=modules,\n",
        "                integration_rules=data[\"general_manual\"][\"integration_rules\"]\n",
        "            )\n",
        "            specific = [SpecificManual(**m) for m in data[\"specific_manuals\"]]\n",
        "\n",
        "            arch = Architecture(\n",
        "                project_name=data[\"project_name\"],\n",
        "                general_manual=general,\n",
        "                specific_manuals=specific\n",
        "            )\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"\\nâœ“ Project: {arch.project_name}\")\n",
        "                print(f\"âœ“ Goal: {arch.general_manual.goal}\")\n",
        "                print(f\"âœ“ Modules: {len(arch.general_manual.modules)}\")\n",
        "                for i, m in enumerate(arch.general_manual.modules, 1):\n",
        "                    reads = f\" ðŸ“–{m.shared_state_reads}\" if m.shared_state_reads else \"\"\n",
        "                    writes = f\" âœï¸{m.shared_state_writes}\" if m.shared_state_writes else \"\"\n",
        "                    print(f\"   {i}. {m.name}{reads}{writes}\")\n",
        "\n",
        "            return arch\n",
        "\n",
        "        except Exception as e:\n",
        "            if verbose:\n",
        "                print(f\"âš ï¸  Parsing failed, using fallback: {e}\")\n",
        "            return self._create_fallback_architecture(task)\n",
        "\n",
        "    def _create_fallback_architecture(self, task: str) -> Architecture:\n",
        "        \"\"\"Simplified architecture\"\"\"\n",
        "        return Architecture(\n",
        "            project_name=f\"Project: {task[:30]}\",\n",
        "            general_manual=GeneralManual(\n",
        "                goal=task,\n",
        "                modules=[\n",
        "                    ModuleSpec(\n",
        "                        id=\"mod_main\",\n",
        "                        name=\"Implementation\",\n",
        "                        description=task,\n",
        "                        inputs=\"Requirements\",\n",
        "                        outputs=\"Solution\",\n",
        "                        dependencies=[],\n",
        "                        rules=\"Be comprehensive\"\n",
        "                    )\n",
        "                ],\n",
        "                integration_rules=\"Return result\"\n",
        "            ),\n",
        "            specific_manuals=[\n",
        "                SpecificManual(\n",
        "                    module_id=\"mod_main\",\n",
        "                    manual_text=f\"Execute: {task}\"\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def _execution_phase(self, architecture: Architecture, verbose: bool) -> List[ModuleArtifact]:\n",
        "        artifacts = []\n",
        "        manuals_map = {m.module_id: m for m in architecture.specific_manuals}\n",
        "\n",
        "        for module_spec in architecture.general_manual.modules:\n",
        "            if verbose:\n",
        "                print(f\"\\nðŸŽ¯ {module_spec.name}\")\n",
        "\n",
        "            context = self.context_manager.get_shared_context(module_spec.shared_state_reads)\n",
        "\n",
        "            if context and verbose:\n",
        "                print(f\"   ðŸ“– Reading context: {list(context.keys())}\")\n",
        "\n",
        "            manual = manuals_map.get(module_spec.id)\n",
        "            manual_text = manual.manual_text if manual else module_spec.description\n",
        "\n",
        "            context_text = \"\"\n",
        "            if context:\n",
        "                context_text = \"\\n\\nAVAILABLE CONTEXT (from previous modules):\\n\"\n",
        "                for key, value in context.items():\n",
        "                    context_text += f\"- {key}: {json.dumps(value, ensure_ascii=False)}\\n\"\n",
        "\n",
        "            prompt = f\"\"\"MODULE: {module_spec.name}\n",
        "\n",
        "MANUAL:\n",
        "{manual_text}{context_text}\n",
        "\n",
        "RULES:\n",
        "{module_spec.rules}\n",
        "\n",
        "Execute this task. If you generate data that other modules need, list them at the end in the format:\n",
        "SHARED_STATE_UPDATE:\n",
        "{{\n",
        "  \"key1\": \"value1\",\n",
        "  \"key2\": [\"item1\", \"item2\"]\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "            content = self.llm.generate(prompt, max_tokens=_MAX_TOKEN_)\n",
        "\n",
        "            updates = self._extract_shared_state_updates(content)\n",
        "\n",
        "            if updates:\n",
        "                self.context_manager.update_shared_state(updates)\n",
        "                if verbose:\n",
        "                    print(f\"   âœï¸ Wrote: {list(updates.keys())}\")\n",
        "\n",
        "            artifact = ModuleArtifact(\n",
        "                module_id=module_spec.id,\n",
        "                name=module_spec.name,\n",
        "                content=content,\n",
        "                shared_state_updates=updates\n",
        "            )\n",
        "\n",
        "            self.context_manager.save_artifact(artifact)\n",
        "            artifacts.append(artifact)\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"   âœ“ Generated ({len(content)} chars)\")\n",
        "\n",
        "        return artifacts\n",
        "\n",
        "    def _extract_shared_state_updates(self, content: str) -> Dict[str, Any]:\n",
        "        try:\n",
        "            marker = \"SHARED_STATE_UPDATE:\"\n",
        "            if marker in content:\n",
        "                start = content.find(marker) + len(marker)\n",
        "                json_start = content.find(\"{\", start)\n",
        "                if json_start != -1:\n",
        "                    brace_count = 0\n",
        "                    json_end = json_start\n",
        "                    for i, char in enumerate(content[json_start:], json_start):\n",
        "                        if char == '{':\n",
        "                            brace_count += 1\n",
        "                        elif char == '}':\n",
        "                            brace_count -= 1\n",
        "                            if brace_count == 0:\n",
        "                                json_end = i + 1\n",
        "                                break\n",
        "\n",
        "                    json_str = content[json_start:json_end]\n",
        "                    return json.loads(json_str)\n",
        "        except Exception as e:\n",
        "            print(f\"   âš ï¸  Failed to extract shared_state: {e}\")\n",
        "\n",
        "        return {}\n",
        "\n",
        "    def _assembly_phase(self, architecture: Architecture, artifacts: List[ModuleArtifact], verbose: bool) -> str:\n",
        "        if verbose:\n",
        "            print(\"ðŸ”— Integrating artifacts...\")\n",
        "\n",
        "        artifacts_text = \"\"\n",
        "        for artifact in artifacts:\n",
        "            artifacts_text += f\"\\n{'='*60}\\n{artifact.name}\\n{'='*60}\\n{artifact.content}\\n\"\n",
        "\n",
        "        shared_state_text = json.dumps(self.context_manager.shared_state, indent=2, ensure_ascii=False)\n",
        "\n",
        "        prompt = f\"\"\"PROJECT: {architecture.project_name}\n",
        "\n",
        "INTEGRATION RULES:\n",
        "{architecture.general_manual.integration_rules}\n",
        "\n",
        "SHARED STATE (Contracts between modules):\n",
        "{shared_state_text}\n",
        "\n",
        "ARTIFACTS:\n",
        "{artifacts_text}\n",
        "\n",
        "Integrate the artifacts following the rules. Use the SHARED STATE to ensure that IDs, APIs and contracts are consistent.\"\"\"\n",
        "\n",
        "        return self.llm.generate(prompt, max_tokens=2000)\n",
        "\n",
        "    def _display_results(self, arch: Architecture, artifacts: List[ModuleArtifact], final: str):\n",
        "        \"\"\"Formatted display\"\"\"\n",
        "        print(f\"\\nðŸ“¦ {arch.project_name}\")\n",
        "        print(f\"ðŸŽ¯ {arch.general_manual.goal}\")\n",
        "        print(f\"\\nðŸ“‚ Artifacts: {len(artifacts)}\")\n",
        "        print(f\"ðŸ§  SharedState Keys: {list(self.context_manager.shared_state.keys())}\")\n",
        "        print(f\"\\nðŸ”— Integrated Result:\")\n",
        "        print(\"-\" * 80)\n",
        "        print(final)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZsxF_QAV0J7T",
      "metadata": {
        "id": "ZsxF_QAV0J7T"
      },
      "source": [
        "# **TODO LIST**\n",
        "- [ ] TOON format for back-prompt\n",
        "- [ ] Extensive JSONs manual maybe isn't necessary (only shared context + how many files + file names + detailed prompt to generate)\n",
        "- [ ] Back-prompt improves (chineses maybe)\n",
        "- [ ] Script for create correctly file extensions (extract from \\`\\`\\` language `content`\\`\\`\\`)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r_-6Z4qhuqeR",
      "metadata": {
        "id": "r_-6Z4qhuqeR"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n",
        "\n",
        "llm = LocalLLM(\"mistralai/Mistral-7B-Instruct-v0.3\")\n",
        "orchestrator = MatrioskaOrchestrator(llm, base_path=\"/content\")\n",
        "\n",
        "result = orchestrator.run(input(\"Enter your prompt: \"))\n",
        "\n",
        "import json\n",
        "with open('/content/matrioska_checkpoints/shared_state.json', 'r') as f:\n",
        "    shared_state = json.load(f)\n",
        "print(json.dumps(shared_state, indent=2))\n",
        "\n",
        "from google.colab import files\n",
        "!zip -r matrioska_results.zip /content/matrioska_artifacts /content/matrioska_checkpoints\n",
        "files.download('matrioska_results.zip')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
