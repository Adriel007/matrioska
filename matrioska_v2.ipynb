{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3uw0inKtuNS0",
      "metadata": {
        "id": "3uw0inKtuNS0"
      },
      "source": [
        "## **Matrioska v2 - LLM Orchestration System with File-Based Architecture**\n",
        "![Matrioska](https://live.staticflickr.com/8646/16075618524_6f3b5b199e_b.jpg)\n",
        "\n",
        "-----\n",
        "\n",
        "### ðŸ‘¤ Author: **Adriel D. S. Andrade**\n",
        "- [LinkedIn](https://www.linkedin.com/in/adriel-domingues-de-souza-andrade/)\n",
        "\n",
        "- [Github repo](https://github.com/adriel007/matrioska)\n",
        "\n",
        "- [Google Colab](https://colab.research.google.com/drive/1Vq3b7Xu5z2Un0n3_6_dQVYWQrX4fsK0j)\n",
        "\n",
        "### ðŸ“‹ Overview\n",
        "\n",
        "Matrioska v2 is an **advanced orchestration system for large language models (LLMs)** that implements a modular architecture based on files with shared state. Inspired by the concept of Russian nesting dolls, the system decomposes complex tasks into specialized files that communicate via a **shared whiteboard** (`shared_state`).\n",
        "\n",
        "-----\n",
        "\n",
        "### ðŸŽ¯ Key Features\n",
        "\n",
        "  * **ðŸ“ File-Based Architecture:** Automatic decomposition of projects into ordered files.\n",
        "  * **ðŸ§  Shared State:** Communication system between files via `shared_state`.\n",
        "  * **ðŸ’¾ Full Persistence:** Checkpoints of architecture and state between executions.\n",
        "  * **âš¡ Sequential Generation:** Each file is generated in dependency order.\n",
        "  * **ðŸ”— Selective Context:** Files access only relevant information from predecessors.\n",
        "  * **ðŸ“¦ Optimized Code:** Focus on minimal, complete, and efficient code using CDNs.\n",
        "\n",
        "-----\n",
        "\n",
        "### ðŸ—ï¸ Architecture\n",
        "\n",
        "#### Core Components\n",
        "\n",
        "  * **`LocalLLM`** - Wrapper for Mistral models with 4-bit quantization.\n",
        "  * **`MatrioskaOrchestrator`** - Main pipeline orchestrator.\n",
        "  * **`ContextManager`** - Manages shared state and persistence.\n",
        "  * **`Architecture`** - Data structure for file-based planning.\n",
        "  * **`FileSpec`** - Individual file specification.\n",
        "  * **`FileArtifact`** - Generated file artifact.\n",
        "\n",
        "#### Execution Flow\n",
        "\n",
        "$$\n",
        "\\begin{array}{ccc}\n",
        "\\text{PHASE 1: ARCHITECTURE} & \\rightarrow & \\text{PHASE 2: CODE GENERATION} \\\\\n",
        "\\downarrow & & \\downarrow \\\\\n",
        "\\text{File Decomposition} & & \\text{Sequential Generation} \\\\\n",
        "& & \\text{by Order/Dependency}\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "-----\n",
        "\n",
        "### ðŸš€ How to Use\n",
        "\n",
        "#### Installation\n",
        "\n",
        "```bash\n",
        "pip install -q json-repair transformers accelerate bitsandbytes torch sentencepiece protobuf\n",
        "```\n",
        "\n",
        "#### Environment Cleanup (Optional)\n",
        "\n",
        "```bash\n",
        "!rm -rf /content/log\n",
        "!rm -rf /content/matrioska_artifacts\n",
        "!rm -rf /content/matrioska_checkpoints\n",
        "```\n",
        "\n",
        "#### Basic Execution\n",
        "\n",
        "```python\n",
        "from matrioska_v2 import LocalLLM, MatrioskaOrchestrator\n",
        "\n",
        "# Initialize model\n",
        "llm = LocalLLM(\"mistralai/Mistral-7B-Instruct-v0.3\")\n",
        "orchestrator = MatrioskaOrchestrator(llm, base_path=\"/content\")\n",
        "\n",
        "# Execute task\n",
        "result = orchestrator.run(\"Create a library management system with authentication and dashboard\")\n",
        "```\n",
        "\n",
        "#### Directory Structure\n",
        "\n",
        "```\n",
        "/content/\n",
        "â”œâ”€â”€ log/                        # Prompt and response logs\n",
        "â”‚   â””â”€â”€ log.txt                # Complete generation history\n",
        "â”œâ”€â”€ matrioska_artifacts/        # Generated files\n",
        "â”‚   â”œâ”€â”€ index.html\n",
        "â”‚   â”œâ”€â”€ styles.css\n",
        "â”‚   â””â”€â”€ app.js\n",
        "â””â”€â”€ matrioska_checkpoints/      # State and architecture\n",
        "    â”œâ”€â”€ shared_state.json       # Shared whiteboard\n",
        "    â””â”€â”€ architecture.json       # Architectural plan\n",
        "```\n",
        "\n",
        "-----\n",
        "\n",
        "### ðŸ“– File System\n",
        "\n",
        "#### File Specification (`FileSpec`)\n",
        "\n",
        "```python\n",
        "@dataclass\n",
        "class FileSpec:\n",
        "    name: str                          # Name without extension\n",
        "    extension: str                     # File extension\n",
        "    order: int                         # Creation order (1, 2, 3...)\n",
        "    shared_state_writes: List[str]     # Info this file defines\n",
        "    shared_state_reads: List[str]      # Info this file needs\n",
        "    content: str                       # Code generation prompt\n",
        "    details: str                       # Functional requirements\n",
        "```\n",
        "\n",
        "#### Architecture Example\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"instructs\": {\n",
        "    \"files\": [\n",
        "      {\n",
        "        \"name\": \"index\",\n",
        "        \"extension\": \"html\",\n",
        "        \"order\": 1,\n",
        "        \"shared_state_writes\": [\"element_ids\", \"page_structure\"],\n",
        "        \"shared_state_reads\": [],\n",
        "        \"content\": \"Generate complete HTML structure for library system...\",\n",
        "        \"details\": \"Responsive layout, login form, book catalog, dashboard\"\n",
        "      },\n",
        "      {\n",
        "        \"name\": \"styles\",\n",
        "        \"extension\": \"css\",\n",
        "        \"order\": 2,\n",
        "        \"shared_state_writes\": [\"css_classes\", \"color_scheme\"],\n",
        "        \"shared_state_reads\": [\"element_ids\", \"page_structure\"],\n",
        "        \"content\": \"Generate complete CSS using Tailwind CDN...\",\n",
        "        \"details\": \"Modern design, dark mode, mobile-first\"\n",
        "      },\n",
        "      {\n",
        "        \"name\": \"app\",\n",
        "        \"extension\": \"js\",\n",
        "        \"order\": 3,\n",
        "        \"shared_state_writes\": [\"api_endpoints\", \"storage_keys\"],\n",
        "        \"shared_state_reads\": [\"element_ids\", \"css_classes\"],\n",
        "        \"content\": \"Generate JavaScript with authentication logic...\",\n",
        "        \"details\": \"JWT auth, localStorage, CRUD operations\"\n",
        "      }\n",
        "    ]\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "#### Shared State Communication Example\n",
        "\n",
        "```\n",
        "# File 1 (HTML) generates IDs\n",
        "SHARED_STATE_UPDATE:\n",
        "{\n",
        "  \"element_ids\": [\"#loginForm\", \"#bookList\", \"#dashboardStats\"],\n",
        "  \"page_structure\": {\n",
        "    \"login\": \"section#login\",\n",
        "    \"catalog\": \"section#catalog\",\n",
        "    \"dashboard\": \"section#dashboard\"\n",
        "  }\n",
        "}\n",
        "\n",
        "# File 2 (CSS) automatically consumes IDs\n",
        "# The ContextManager provides only the keys specified in shared_state_reads\n",
        "```\n",
        "\n",
        "-----\n",
        "\n",
        "### ðŸ”§ Model Configuration\n",
        "\n",
        "#### 4-bit Quantization\n",
        "\n",
        "```python\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        ")\n",
        "```\n",
        "\n",
        "#### Generation Parameters\n",
        "\n",
        "  * `max_new_tokens`: 20,000 (configurable via `_MAX_TOKEN_`)\n",
        "  * `temperature`: 0.3\n",
        "  * `top_p`: 0.85\n",
        "  * `do_sample`: True\n",
        "  * `pad_token_id`: Auto (`eos_token_id`)\n",
        "\n",
        "-----\n",
        "\n",
        "### ðŸ“Š Architecture Prompt\n",
        "\n",
        "The system uses **`ARCHITECT_SYSTEM_PROMPT`** which instructs the LLM to:\n",
        "\n",
        "  * Decompose the task into independent files\n",
        "  * Define creation order based on dependencies\n",
        "  * Specify contracts via `shared_state_reads`/`writes`\n",
        "  * Generate complete prompts for each file\n",
        "  * Focus on minimal code and use of CDNs/libraries\n",
        "\n",
        "#### Mandatory Prompt Rules\n",
        "\n",
        "  * Strict JSON structure with `instructs` root\n",
        "  * `order` field defining creation sequence\n",
        "  * `shared_state_writes`: information the file defines\n",
        "  * `shared_state_reads`: information the file needs\n",
        "  * `content`: complete code generation prompt\n",
        "  * `details`: functional and non-functional requirements\n",
        "\n",
        "-----\n",
        "\n",
        "### ðŸ’¡ Use Cases\n",
        "\n",
        "#### Complete Web System\n",
        "\n",
        "```python\n",
        "result = orchestrator.run('''\n",
        "Create a complete e-commerce system with:\n",
        "- Product catalog with search\n",
        "- Shopping cart functionality\n",
        "- User authentication\n",
        "- Admin dashboard\n",
        "- Responsive design with Tailwind CDN\n",
        "''')\n",
        "```\n",
        "\n",
        "#### React/Vue Application\n",
        "\n",
        "```python\n",
        "result = orchestrator.run('''\n",
        "Build a task management app using React CDN with:\n",
        "- Component-based architecture\n",
        "- State management\n",
        "- CRUD operations\n",
        "- LocalStorage persistence\n",
        "''')\n",
        "```\n",
        "\n",
        "#### Data Dashboard\n",
        "\n",
        "```python\n",
        "result = orchestrator.run('''\n",
        "Create an analytics dashboard with:\n",
        "- Chart.js for visualizations\n",
        "- Real-time data updates\n",
        "- Export to CSV functionality\n",
        "- Responsive grid layout\n",
        "''')\n",
        "```\n",
        "\n",
        "-----\n",
        "\n",
        "### ðŸŽ¨ Output Example\n",
        "\n",
        "```\n",
        "================================================================================\n",
        "ðŸª† MATRIOSKA ORCHESTRATOR - File-Based Architecture\n",
        "================================================================================\n",
        "\n",
        "ðŸ—ï¸  PHASE 1: ARCHITECTURE\n",
        "--------------------------------------------------------------------------------\n",
        "ðŸ“‹ Task: 'Create a library management system with authentication and dashboard'\n",
        "\n",
        "âœ“ Project: Project_3_Files\n",
        "âœ“ Files: 3\n",
        "   1. index.html ðŸ“–[] âœï¸['element_ids', 'page_structure']\n",
        "   2. styles.css ðŸ“–['element_ids', 'page_structure'] âœï¸['css_classes', 'color_scheme']\n",
        "   3. app.js ðŸ“–['element_ids', 'css_classes'] âœï¸['api_endpoints', 'storage_keys']\n",
        "\n",
        "âš¡ PHASE 2: CODE GENERATION\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "ðŸŽ¯ Generating: index.html (Order: 1)\n",
        "ðŸ’¾ index.html â†’ /content/matrioska_artifacts/index.html\n",
        "ðŸ§  [SHARED STATE] Updated: ['element_ids', 'page_structure']\n",
        "   âœï¸ Wrote: ['element_ids', 'page_structure']\n",
        "   âœ“ Generated (2847 chars)\n",
        "\n",
        "ðŸŽ¯ Generating: styles.css (Order: 2)\n",
        "   ðŸ“– Reading context: ['element_ids', 'page_structure']\n",
        "ðŸ’¾ styles.css â†’ /content/matrioska_artifacts/styles.css\n",
        "ðŸ§  [SHARED STATE] Updated: ['css_classes', 'color_scheme']\n",
        "   âœï¸ Wrote: ['css_classes', 'color_scheme']\n",
        "   âœ“ Generated (1923 chars)\n",
        "\n",
        "ðŸŽ¯ Generating: app.js (Order: 3)\n",
        "   ðŸ“– Reading context: ['element_ids', 'css_classes']\n",
        "ðŸ’¾ app.js â†’ /content/matrioska_artifacts/app.js\n",
        "ðŸ§  [SHARED STATE] Updated: ['api_endpoints', 'storage_keys']\n",
        "   âœï¸ Wrote: ['api_endpoints', 'storage_keys']\n",
        "   âœ“ Generated (3456 chars)\n",
        "\n",
        "âœ… FINAL RESULT\n",
        "================================================================================\n",
        "\n",
        "ðŸ“¦ Project_3_Files\n",
        "\n",
        "ðŸ“‚ Generated Files: 3\n",
        "   1. index.html\n",
        "   2. styles.css\n",
        "   3. app.js\n",
        "\n",
        "ðŸ§  SharedState Keys: ['element_ids', 'page_structure', 'css_classes', 'color_scheme', 'api_endpoints', 'storage_keys']\n",
        "================================================================================\n",
        "\n",
        "ðŸ“ Artifacts: /content/matrioska_artifacts\n",
        "ðŸ§  SharedState: /content/matrioska_checkpoints/shared_state.json\n",
        "```\n",
        "\n",
        "-----\n",
        "\n",
        "### ðŸ”„ State Management\n",
        "\n",
        "#### Shared State\n",
        "\n",
        "  * **Persistent:** Saved in `shared_state.json` between executions.\n",
        "  * **Structured:** JSON-serializable dictionary.\n",
        "  * **Selective:** Files access only keys specified in `shared_state_reads`.\n",
        "  * **Incremental:** Updated during the generation of each file.\n",
        "\n",
        "#### Checkpoints\n",
        "\n",
        "  * **Architecture:** `architecture.json` - Complete project plan\n",
        "  * **SharedState:** `shared_state.json` - Current shared state\n",
        "  * **Artifacts:** Individual files in `matrioska_artifacts/`\n",
        "  * **Logs:** Complete history of prompts and responses in `log/log.txt`\n",
        "\n",
        "#### Shared State Example (`shared_state.json`)\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"element_ids\": [\"#loginForm\", \"#bookList\", \"#dashboard\"],\n",
        "  \"page_structure\": {\n",
        "    \"login\": \"section#login\",\n",
        "    \"catalog\": \"section#catalog\"\n",
        "  },\n",
        "  \"css_classes\": [\"btn-primary\", \"card\", \"nav-item\"],\n",
        "  \"color_scheme\": {\n",
        "    \"primary\": \"#3b82f6\",\n",
        "    \"secondary\": \"#8b5cf6\"\n",
        "  },\n",
        "  \"api_endpoints\": {\n",
        "    \"login\": \"/api/auth/login\",\n",
        "    \"books\": \"/api/books\"\n",
        "  },\n",
        "  \"storage_keys\": [\"authToken\", \"currentUser\"]\n",
        "}\n",
        "```\n",
        "\n",
        "#### ðŸ“¦ SharedState Updates Extraction\n",
        "\n",
        "The system automatically detects updates in the format:\n",
        "\n",
        "```\n",
        "// At the end of the generated code\n",
        "SHARED_STATE_UPDATE:\n",
        "{\n",
        "  \"key1\": \"value1\",\n",
        "  \"key2\": [\"item1\", \"item2\"]\n",
        "}\n",
        "```\n",
        "\n",
        "This marker is:\n",
        "\n",
        "  * Extracted and processed by the `ContextManager`\n",
        "  * Removed from the final code\n",
        "  * Persisted in `shared_state.json`\n",
        "\n",
        "#### ðŸ“„ Returned API\n",
        "\n",
        "```python\n",
        "result = orchestrator.run(\"Create app...\")\n",
        "\n",
        "# Returns a dictionary with:\n",
        "{\n",
        "  \"architecture\": Architecture,     # Object with the project plan\n",
        "  \"artifacts\": List[FileArtifact], # List of generated files\n",
        "  \"shared_state\": Dict[str, Any]   # Final shared state\n",
        "}\n",
        "```\n",
        "\n",
        "-----\n",
        "\n",
        "### ðŸ› ï¸ Technical Requirements\n",
        "\n",
        "  * **GPU:** NVIDIA T4 (8GB VRAM) or superior\n",
        "  * **RAM:** 12GB+ recommended\n",
        "  * **Python:** 3.8+\n",
        "  * **Libraries:**\n",
        "      * `transformers` (Hugging Face)\n",
        "      * `torch` (PyTorch)\n",
        "      * `bitsandbytes` (Quantization)\n",
        "      * `accelerate` (Optimization)\n",
        "      * `json-repair` (Robust Parsing)\n",
        "      * `sentencepiece`, `protobuf` (Tokenization)\n",
        "\n",
        "-----\n",
        "\n",
        "### ðŸ” Logging and Debug\n",
        "\n",
        "All prompts and responses are saved in `/content/log/log.txt`:\n",
        "\n",
        "```\n",
        "PROMPT:\n",
        "==========================================\n",
        "[Complete prompt sent to LLM]\n",
        "==========================================\n",
        "RESULT:\n",
        "==========================================\n",
        "[LLM Response]\n",
        "```\n",
        "\n",
        "-----\n",
        "\n",
        "### ðŸŽ¯ Best Practices\n",
        "\n",
        "  * **File Order:** HTML/DB first â†’ CSS/Styles â†’ JS/Logic â†’ API/Backend\n",
        "  * **SharedState:** Define clear contracts between files (IDs, classes, routes)\n",
        "  * **Detailed Prompts:** The `content` field must be a complete generation prompt\n",
        "  * **CDNs:** Prioritize libraries via CDN to reduce complexity\n",
        "  * **Minimal Code:** Focus on minimal and functional code\n",
        "\n",
        "-----\n",
        "\n",
        "### ðŸ”® Differences from v1\n",
        "\n",
        "| Aspect | v1 (Modules) | v2 (Files) |\n",
        "| :--- | :--- | :--- |\n",
        "| **Basic Unit** | `ModuleSpec` | `FileSpec` |\n",
        "| **Final Integration** | Artifact assembly | Independent files |\n",
        "| **Structure** | 3 phases | 2 phases |\n",
        "| **Focus** | Conceptual modularity | Practical code generation |\n",
        "| **Output** | Integrated result | Separate files |\n",
        "\n",
        "-----\n",
        "\n",
        "### ðŸ“„ License\n",
        "\n",
        "This project is intended for research and educational development purposes.\n",
        "\n",
        "**Matrioska v2: Transforming ideas into structured code ðŸª†âœ¨**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8Y6IqCbauRxi",
      "metadata": {
        "id": "8Y6IqCbauRxi"
      },
      "outputs": [],
      "source": [
        "!pip install -q json-repair transformers accelerate bitsandbytes torch sentencepiece protobuf # requirements.txt with specific versions in github repo\n",
        "!cd /content/\n",
        "!rm -rf /content/log\n",
        "!rm -rf /content/matrioska_artifacts\n",
        "!rm -rf /content/matrioska_checkpoints\n",
        "\n",
        "import json\n",
        "import os\n",
        "import torch\n",
        "from json_repair import repair_json\n",
        "from dataclasses import dataclass, asdict, field\n",
        "from typing import List, Optional, Dict, Any\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62PMVQKnz_Kl",
      "metadata": {
        "id": "62PMVQKnz_Kl"
      },
      "outputs": [],
      "source": [
        "_MAX_TOKEN_ = 20_000\n",
        "\n",
        "ARCHITECT_SYSTEM_PROMPT = \"\"\"You are Matrioska Architect. Decompose user requests into isolated modules that communicate via shared_state.\n",
        "\n",
        "**OUTPUT FORMAT RULES (Mandatory):**\n",
        "\n",
        "1.  **Structure:** The output **MUST** be a strict JSON object following the format below.\n",
        "2.  **Root Object:** The root object **MUST** be named `instructs`.\n",
        "3.  **Order (`order`):** Assign an integer starting from 1 to indicate the **creation order** of files (e.g., HTML/DB first, then CSS/JS/API logic).\n",
        "4.  **Shared Information (`shared_state_reads/writes`):**\n",
        "    * `shared_state_writes`: List **key information** this file defines (e.g., \"HTML element IDs,\" \"CSS class names,\" \"API endpoint routes\").\n",
        "    * `shared_state_reads`: List **key information** this file requires from previous files in the `order` (e.g., CSS reads \"HTML element IDs\").\n",
        "5.  **Content Requirement (`content`):** Must contain a **complete and detailed prompt** for a coding AI, demanding the generation of **full, reduced, and efficient code**. Explicitly instruct the use of **CDNs and lightweight libraries**.\n",
        "6.  **Details (`details`):** Must contain a concise list of **functional and non-functional requirements**.\n",
        "\n",
        "**Mandatory Output Structure:**\n",
        "\n",
        "{\n",
        "  \"instructs\": {\n",
        "    \"files\": [\n",
        "      {\n",
        "        \"name\": \"[FILE_NAME_WITHOUT_EXTENSION]\",\n",
        "        \"extension\": \"[EXTENSION]\",\n",
        "        \"order\": 1,\n",
        "        \"shared_state_writes\": [\"[INFO_DEFINED_BY_THIS_FILE]\"],\n",
        "        \"shared_state_reads\": [\"[INFO_NEEDED_FROM_OTHER_FILES]\"],\n",
        "        \"content\": \"[DETAILED PROMPT FOR A CODING AI TO GENERATE THE ENTIRE CODE, FOCUSING ON BEING REDUCED, COMPLETE, AND USING CDNS/LIBRARIES IF NOT SPECIFIED]\",\n",
        "        \"details\": \"[CONCISE FUNCTIONAL AND NON-FUNCTIONAL REQUIREMENTS]\"\n",
        "      }\n",
        "    ]\n",
        "  }\n",
        "}\n",
        "\n",
        "NOW PROCESS THIS REQUEST:\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nhHdTyXvtzUF",
      "metadata": {
        "id": "nhHdTyXvtzUF"
      },
      "outputs": [],
      "source": [
        "class LocalLLM:\n",
        "    def __init__(self, model_name: str = \"mistralai/Mistral-7B-Instruct-v0.3\"):\n",
        "        print(f\"ðŸ”„ Loading {model_name}...\")\n",
        "\n",
        "        quant_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_compute_dtype=torch.float16,\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "            bnb_4bit_quant_type=\"nf4\"\n",
        "        )\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            quantization_config=quant_config,\n",
        "            device_map=\"auto\",\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        self.model_name = model_name\n",
        "        print(f\"âœ… Model loaded: {model_name}\")\n",
        "        print(f\"ðŸ’¾ VRAM used: {torch.cuda.memory_allocated()/1024**3:.2f}GB\")\n",
        "\n",
        "    def generate(self, prompt: str, max_tokens: int = _MAX_TOKEN_, system: str = \"\") -> str:\n",
        "        if system:\n",
        "            full_prompt = f\"{system}\\n\\n{prompt}\"\n",
        "        else:\n",
        "            full_prompt = prompt\n",
        "\n",
        "        inputs = self.tokenizer(full_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=max_tokens,\n",
        "                temperature=0.3,\n",
        "                top_p=0.85,\n",
        "                do_sample=True,\n",
        "                pad_token_id=self.tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        response = self.tokenizer.decode(\n",
        "            outputs[0][inputs['input_ids'].shape[1]:],\n",
        "            skip_special_tokens=True\n",
        "        )\n",
        "\n",
        "        log_dir = \"/content/log\"\n",
        "        log_file = os.path.join(log_dir, \"log.txt\")\n",
        "        os.makedirs(log_dir, exist_ok=True)\n",
        "        with open(log_file, \"a\") as f:\n",
        "            f.write(\"PROMPT:\\n==========================================\\n\\n\")\n",
        "            f.write(full_prompt)\n",
        "            f.write(\"\\n==========================================\\n\")\n",
        "            f.write(\"RESULT:\\n==========================================\\n\\n\")\n",
        "            f.write(response.strip())\n",
        "            f.write(\"\\n\\n\\n\\n\")\n",
        "\n",
        "        return response.strip()\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class FileSpec:\n",
        "    name: str\n",
        "    extension: str\n",
        "    order: int\n",
        "    shared_state_writes: List[str] = field(default_factory=list)\n",
        "    shared_state_reads: List[str] = field(default_factory=list)\n",
        "    content: str = \"\"\n",
        "    details: str = \"\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Architecture:\n",
        "    project_name: str\n",
        "    files: List[FileSpec]\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class FileArtifact:\n",
        "    name: str\n",
        "    extension: str\n",
        "    order: int\n",
        "    content: str\n",
        "    shared_state_updates: Dict[str, Any] = field(default_factory=dict)\n",
        "\n",
        "\n",
        "class ContextManager:\n",
        "    def __init__(self, base_path: str = \"/content\"):\n",
        "        self.base_path = base_path\n",
        "        self.artifacts_dir = os.path.join(base_path, \"matrioska_artifacts\")\n",
        "        self.checkpoints_dir = os.path.join(base_path, \"matrioska_checkpoints\")\n",
        "        self.shared_state_file = os.path.join(self.checkpoints_dir, \"shared_state.json\")\n",
        "\n",
        "        os.makedirs(self.artifacts_dir, exist_ok=True)\n",
        "        os.makedirs(self.checkpoints_dir, exist_ok=True)\n",
        "\n",
        "        self.shared_state: Dict[str, Any] = self._load_shared_state()\n",
        "\n",
        "    def _load_shared_state(self) -> Dict[str, Any]:\n",
        "        try:\n",
        "            with open(self.shared_state_file, \"r\", encoding=\"utf-8\") as f:\n",
        "                state = json.load(f)\n",
        "                print(\"ðŸ§  [SHARED STATE] Context recovered\")\n",
        "                return state\n",
        "        except FileNotFoundError:\n",
        "            print(\"ðŸ§  [SHARED STATE] Starting new context\")\n",
        "            return {}\n",
        "\n",
        "    def _save_shared_state(self):\n",
        "        with open(self.shared_state_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(self.shared_state, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    def update_shared_state(self, updates: Dict[str, Any]):\n",
        "        self.shared_state.update(updates)\n",
        "        self._save_shared_state()\n",
        "        print(f\"ðŸ§  [SHARED STATE] Updated: {list(updates.keys())}\")\n",
        "\n",
        "    def get_shared_context(self, keys: List[str]) -> Dict[str, Any]:\n",
        "        context = {}\n",
        "        for key in keys:\n",
        "            if key in self.shared_state:\n",
        "                context[key] = self.shared_state[key]\n",
        "        return context\n",
        "\n",
        "    def save_architecture(self, arch: Architecture):\n",
        "        filepath = os.path.join(self.checkpoints_dir, \"architecture.json\")\n",
        "        with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump({\n",
        "                \"project_name\": arch.project_name,\n",
        "                \"files\": [asdict(f) for f in arch.files]\n",
        "            }, f, indent=2, ensure_ascii=False)\n",
        "        print(f\"ðŸ’¾ [CHECKPOINT] Architecture â†’ {filepath}\")\n",
        "\n",
        "    def load_architecture(self) -> Optional[Architecture]:\n",
        "        filepath = os.path.join(self.checkpoints_dir, \"architecture.json\")\n",
        "        try:\n",
        "            with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "                data = json.load(f)\n",
        "            files = [FileSpec(**f) for f in data[\"files\"]]\n",
        "            print(\"ðŸ“‚ [RESTORATION] Context recovered\")\n",
        "            return Architecture(\n",
        "                project_name=data[\"project_name\"],\n",
        "                files=files\n",
        "            )\n",
        "        except FileNotFoundError:\n",
        "            return None\n",
        "\n",
        "    def save_artifact(self, artifact: FileArtifact):\n",
        "        filename = os.path.join(self.artifacts_dir, f\"{artifact.name}.{artifact.extension}\")\n",
        "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(artifact.content)\n",
        "        print(f\"ðŸ’¾ {artifact.name}.{artifact.extension} â†’ {filename}\")\n",
        "\n",
        "    def get_artifacts_path(self) -> str:\n",
        "        return self.artifacts_dir\n",
        "\n",
        "\n",
        "class MatrioskaOrchestrator:\n",
        "    def __init__(self, llm: LocalLLM, base_path: str = \"/content\"):\n",
        "        self.llm = llm\n",
        "        self.context_manager = ContextManager(base_path)\n",
        "\n",
        "    def run(self, task: str, verbose: bool = True):\n",
        "        \"\"\"Main pipeline with file-based architecture\"\"\"\n",
        "        if verbose:\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"ðŸª† MATRIOSKA ORCHESTRATOR - File-Based Architecture\")\n",
        "            print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "        if verbose:\n",
        "            print(\"ðŸ—ï¸  PHASE 1: ARCHITECTURE\")\n",
        "            print(\"-\" * 80)\n",
        "        architecture = self._architecture_phase(task, verbose)\n",
        "\n",
        "        if not architecture:\n",
        "            return None\n",
        "\n",
        "        self.context_manager.save_architecture(architecture)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"\\nâš¡ PHASE 2: CODE GENERATION\")\n",
        "            print(\"-\" * 80)\n",
        "        artifacts = self._generation_phase(architecture, verbose)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"\\nâœ… FINAL RESULT\")\n",
        "            print(\"=\" * 80)\n",
        "            self._display_results(architecture, artifacts)\n",
        "            print(\"=\" * 80)\n",
        "            print(f\"\\nðŸ“ Artifacts: {self.context_manager.get_artifacts_path()}\")\n",
        "            print(f\"ðŸ§  SharedState: {self.context_manager.shared_state_file}\")\n",
        "\n",
        "        return {\n",
        "            \"architecture\": architecture,\n",
        "            \"artifacts\": artifacts,\n",
        "            \"shared_state\": self.context_manager.shared_state\n",
        "        }\n",
        "\n",
        "    def _architecture_phase(self, task: str, verbose: bool) -> Optional[Architecture]:\n",
        "        if verbose:\n",
        "            print(f\"ðŸ“‹ Task: '{task}'\")\n",
        "\n",
        "        response = self.llm.generate(task, max_tokens=_MAX_TOKEN_, system=ARCHITECT_SYSTEM_PROMPT)\n",
        "\n",
        "        try:\n",
        "            data = json.loads(repair_json(response))\n",
        "\n",
        "            if \"instructs\" not in data or \"files\" not in data[\"instructs\"]:\n",
        "                raise ValueError(\"Invalid response format: missing 'instructs.files'\")\n",
        "\n",
        "            files = [FileSpec(**f) for f in data[\"instructs\"][\"files\"]]\n",
        "            files.sort(key=lambda x: x.order)\n",
        "\n",
        "            project_name = f\"Project_{len(files)}_Files\"\n",
        "            arch = Architecture(project_name=project_name, files=files)\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"\\nâœ“ Project: {arch.project_name}\")\n",
        "                print(f\"âœ“ Files: {len(arch.files)}\")\n",
        "                for f in arch.files:\n",
        "                    reads = f\" ðŸ“–{f.shared_state_reads}\" if f.shared_state_reads else \"\"\n",
        "                    writes = f\" âœï¸{f.shared_state_writes}\" if f.shared_state_writes else \"\"\n",
        "                    print(f\"   {f.order}. {f.name}.{f.extension}{reads}{writes}\")\n",
        "\n",
        "            return arch\n",
        "\n",
        "        except Exception as e:\n",
        "            if verbose:\n",
        "                print(f\"âš ï¸  Parsing failed: {e}\")\n",
        "                print(f\"Response preview: {response[:500]}...\")\n",
        "            return None\n",
        "\n",
        "    def _generation_phase(self, architecture: Architecture, verbose: bool) -> List[FileArtifact]:\n",
        "        artifacts = []\n",
        "\n",
        "        for file_spec in architecture.files:\n",
        "            if verbose:\n",
        "                print(f\"\\nðŸŽ¯ Generating: {file_spec.name}.{file_spec.extension} (Order: {file_spec.order})\")\n",
        "\n",
        "            context = self.context_manager.get_shared_context(file_spec.shared_state_reads)\n",
        "\n",
        "            if context and verbose:\n",
        "                print(f\"   ðŸ“– Reading context: {list(context.keys())}\")\n",
        "\n",
        "            context_text = \"\"\n",
        "            if context:\n",
        "                context_text = \"\\n\\nAVAILABLE SHARED INFORMATION (from previous files):\\n\"\n",
        "                for key, value in context.items():\n",
        "                    context_text += f\"- {key}: {json.dumps(value, ensure_ascii=False)}\\n\"\n",
        "\n",
        "            prompt = f\"\"\"FILE: {file_spec.name}.{file_spec.extension}\n",
        "\n",
        "GENERATION INSTRUCTIONS:\n",
        "{file_spec.content}{context_text}\n",
        "\n",
        "REQUIREMENTS:\n",
        "{file_spec.details}\n",
        "\n",
        "Generate the COMPLETE, REDUCED, and EFFICIENT code for this file. Use CDNs and lightweight libraries when appropriate.\n",
        "\n",
        "If you define key information that other files need (e.g., element IDs, class names, API routes), list them at the end in the format:\n",
        "SHARED_STATE_UPDATE:\n",
        "{{\n",
        "  \"key1\": \"value1\",\n",
        "  \"key2\": [\"item1\", \"item2\"]\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "            content = self.llm.generate(prompt, max_tokens=_MAX_TOKEN_)\n",
        "\n",
        "            updates = self._extract_shared_state_updates(content)\n",
        "\n",
        "            if updates:\n",
        "                self.context_manager.update_shared_state(updates)\n",
        "                if verbose:\n",
        "                    print(f\"   âœï¸ Wrote: {list(updates.keys())}\")\n",
        "\n",
        "            clean_content = self._remove_shared_state_marker(content)\n",
        "\n",
        "            artifact = FileArtifact(\n",
        "                name=file_spec.name,\n",
        "                extension=file_spec.extension,\n",
        "                order=file_spec.order,\n",
        "                content=clean_content,\n",
        "                shared_state_updates=updates\n",
        "            )\n",
        "\n",
        "            self.context_manager.save_artifact(artifact)\n",
        "            artifacts.append(artifact)\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"   âœ“ Generated ({len(clean_content)} chars)\")\n",
        "\n",
        "        return artifacts\n",
        "\n",
        "    def _extract_shared_state_updates(self, content: str) -> Dict[str, Any]:\n",
        "        try:\n",
        "            marker = \"SHARED_STATE_UPDATE:\"\n",
        "            if marker in content:\n",
        "                after_marker = content[content.find(marker) + len(marker):]\n",
        "                parsed = json.loads(repair_json(after_marker))\n",
        "\n",
        "                if isinstance(parsed, list):\n",
        "                    print(f\"   âš ï¸ SharedState as array, converting to dict\")\n",
        "                    return {\"data_list\": parsed}\n",
        "\n",
        "                if not isinstance(parsed, dict):\n",
        "                    print(f\"   âš ï¸ SharedState is invalid: {type(parsed).__name__}\")\n",
        "                    return {}\n",
        "\n",
        "                return parsed\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   âš ï¸ Failed to extract shared_state: {e}\")\n",
        "\n",
        "        return {}\n",
        "\n",
        "    def _remove_shared_state_marker(self, content: str) -> str:\n",
        "        marker = \"SHARED_STATE_UPDATE:\"\n",
        "        if marker in content:\n",
        "            return content[:content.find(marker)].strip()\n",
        "        return content\n",
        "\n",
        "    def _display_results(self, arch: Architecture, artifacts: List[FileArtifact]):\n",
        "        print(f\"\\nðŸ“¦ {arch.project_name}\")\n",
        "        print(f\"\\nðŸ“‚ Generated Files: {len(artifacts)}\")\n",
        "        for artifact in artifacts:\n",
        "            print(f\"   {artifact.order}. {artifact.name}.{artifact.extension}\")\n",
        "        print(f\"\\nðŸ§  SharedState Keys: {list(self.context_manager.shared_state.keys())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZsxF_QAV0J7T",
      "metadata": {
        "id": "ZsxF_QAV0J7T"
      },
      "source": [
        "# **TODO LIST**\n",
        "- [ ] Script for create correctly file extensions (extract from \\`\\`\\` language `content`\\`\\`\\`)\n",
        "- [ ] Analysis/research prompt model (for reading->abstract tasks, using shared state to save key-words and means)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r_-6Z4qhuqeR",
      "metadata": {
        "id": "r_-6Z4qhuqeR"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n",
        "\n",
        "llm = LocalLLM(\"mistralai/Mistral-7B-Instruct-v0.3\")\n",
        "orchestrator = MatrioskaOrchestrator(llm, base_path=\"/content\")\n",
        "\n",
        "result = orchestrator.run(input(\"Enter your prompt: \"))\n",
        "\n",
        "import json\n",
        "with open('/content/matrioska_checkpoints/shared_state.json', 'r') as f:\n",
        "    shared_state = json.load(f)\n",
        "print(json.dumps(shared_state, indent=2))\n",
        "\n",
        "from google.colab import files\n",
        "!zip -r matrioska_results.zip /content/matrioska_artifacts /content/matrioska_checkpoints\n",
        "files.download('matrioska_results.zip')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
